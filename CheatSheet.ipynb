{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML lab cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Output has been removed for brevity, uncomment to visualize it!\n",
    "\n",
    "**NOTE:** This file only contains very common stuff or code which is not easy remember; don't take this as a complete reference (not yet at least)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual check for decimal separator, delimiter etc.:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"winequality-red.csv\"\n",
    "\n",
    "with open(data_file) as file_:\n",
    "    # print(file_.readline(), '\\n', file_.readline())\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import as a dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file, sep=';', decimal='.')\n",
    "\n",
    "# print(f'Shape of the input data {df.shape}\\n')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example:\n",
    "data_file = 'ex1_4dim_data.csv'\n",
    "df2 = pd.read_csv(data_file, delimiter=',', names=['col1', 'col2', 'col3', 'col4']) # or use: header=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import as numpy array:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array_ = np.loadtxt(data_file, delimiter = ',', skiprows=1)\n",
    "#array_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# here warning are ignored\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same implemented as a handy decorator:\n",
    "def no_warn(decd):\n",
    "    import warnings\n",
    "    def f(*args, **kargs):\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        decd(*args, **kargs)\n",
    "        warnings.resetwarnings()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphically analyze a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understand relations between attributes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# df.hist(figsize = [15,10]); # [x, y]\n",
    "\n",
    "import seaborn as sns\n",
    "# no_warn(sns.pairplot)(df[:10], hue='quality', corner=True);\n",
    "\n",
    "# sns.heatmap(df.corr(), cmap=\"YlGnBu\", annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplots (detect outliers...):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(data = df);\n",
    "\n",
    "# Better, esp. with non-normalized data:\n",
    "def boxplots(df):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(17,10))\n",
    "    pos = 1\n",
    "    for i in df.columns:\n",
    "        plt.subplot(3, 4, pos)\n",
    "        sns.boxplot(x = df[i], width=.5)\n",
    "        pos += 1\n",
    "    plt.show()\n",
    "\n",
    "# boxplots(df)\n",
    "\n",
    "# To compare only two (categ.) atttributes:\n",
    "# sns.boxplot(x='quality', y='fixed acidity', data = df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data for supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ = 'quality'\n",
    "RANDOM_STATE = 44\n",
    "\n",
    "y = df[class_]\n",
    "X = df.drop(columns=class_)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tup = train_test_split(\n",
    "    X, y,\n",
    "    random_state=RANDOM_STATE,\n",
    "    train_size = 0.66             # 0.75 default\n",
    ")\n",
    "\n",
    "n_features = X_train.shape[1]     \n",
    "# assert(n_features==X_test.shape[1])\n",
    "\n",
    "# for _ in Tup: print(end=f'{_.shape} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with decision tree (trivial example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "DTCLASSIF_PARS = {'criterion':'entropy'}\n",
    "\n",
    "def instantiate_and_predict(X_data, y_target, X_to_predict, **pars):\n",
    "    global RANDOM_STATE, DTCLASSIF_PARS\n",
    "    estim = tree.DecisionTreeClassifier(**pars, **DTCLASSIF_PARS, random_state=RANDOM_STATE)\n",
    "    estim.fit(X_data, y_target)\n",
    "    return (estim, estim.predict(X_to_predict))\n",
    "\n",
    "model, tr_predicted = instantiate_and_predict(X_train, y_train, X_train)\n",
    "test_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy and other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def print_accuracy(s1_name, s2):\n",
    "    accur = accuracy_score(eval(s1_name), s2)*100\n",
    "    print(f'The accuracy on {s1_name} is {accur:.4}%')\n",
    "    return accur\n",
    "    \n",
    "# print_accuracy('y_train', tr_predicted)\n",
    "# print_accuracy('y_test', test_predicted);\n",
    "\n",
    "# import sklearn.metrics as skm\n",
    "# sorted([ _ for _ in skm.__all__ if 'score' in _])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "plt.figure(figsize=(17,22))\n",
    "plot_tree(\n",
    "    model,\n",
    "    feature_names=df.columns,\n",
    "    class_names=class_,\n",
    "    rounded = True,\n",
    "    proportion = True\n",
    ")''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Centroids (having the labels)\n",
    "See _Plot Points_ section for examples about these functions. \\\n",
    "See _Elbow Method_ section to know how to compute labels and centroids directly (using KMeans)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The fastest way:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroids2(arr, labels, **args):\n",
    "    from sklearn.neighbors import NearestCentroid\n",
    "    return NearestCentroid(**args).fit(arr, labels).centroids_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without using sklearn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroids(arr, labels, FUN=np.mean):\n",
    "    centroids = []\n",
    "    ulabels = np.unique(labels)\n",
    "    for L in ulabels:\n",
    "        tr = arr[[_==L for _ in labels],:].transpose()\n",
    "        centroids.append([FUN(tr[_]) for _ in range(arr.shape[1])])\n",
    "    return np.array(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just points:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(df2.iloc[:,0:2])\n",
    "\n",
    "'''\n",
    "plt.xlabel(df2.iloc[:,0].name)\n",
    "plt.ylabel(df2.iloc[:,1].name)\n",
    "\n",
    "plt.plot(arr[:,0], arr[:,1], '.')\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clusters (different colors and centroids):** \\\n",
    "( Code by **Claudio Sartori** slightly adapted for compatibility. Originally in plot_clusters.py )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "def plot_clusters(X, y, dim, points,\n",
    "                  labels_prefix = 'cluster ', \n",
    "                  points_name = 'centroids',\n",
    "                  colors = cm.tab10, # a qualitative map\n",
    "                  points_color = cm.tab10(10) # by default the last of the map (to be improved)\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Plot a two dimensional projection of an array of labelled points\n",
    "    X:      array with at least two columns\n",
    "    y:      vector of labels, length as number of rows in X\n",
    "    dim:    the two columns to project, inside range of X columns, e.g. (0,1)\n",
    "    points: additional points to plot as 'stars'\n",
    "    labels_prefix: prefix to the labels for the legend ['cluster']\n",
    "    points_name:   legend name for the additional points ['centroids']\n",
    "    colors: a color map\n",
    "    points_color: the color for the points\n",
    "    \"\"\"\n",
    "    # plot the labelled (colored) dataset and the points\n",
    "    labels = np.unique(y)\n",
    "    for i in range(len(labels)):\n",
    "        color = colors(i / len(labels)) # choose a color from the map\n",
    "        plt.scatter(X[[_==labels[i] for _ in y],dim[0]], \n",
    "                    X[[_==labels[i] for _ in y],dim[1]], \n",
    "                    s=10, c = [color], marker='s', label=labels_prefix+str(labels[i]))\n",
    "    plt.scatter(points[:,dim[0]], points[:,dim[1]], s=50, marker='*', c=[points_color], label=points_name)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "some_rand_labels = ['one' if arr[_][0]<-4.7 else 'two' if arr[_][0]<.7 else 'three' for _ in range(len(arr))]\n",
    "\n",
    "'''\n",
    "plot_clusters(\n",
    "    arr,\n",
    "    some_rand_labels,\n",
    "    (0,1),\n",
    "    centroids2(arr, some_rand_labels)                  # try to add eg: metric='manhattan'\n",
    "    # ALTERNATIVE: centroids(arr, some_rand_labels)    # try to add eg: FUN=np.median\n",
    ")''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elbow Method (includes KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Cicling over different KMeans estimators, one for each value of K in [2,10]:\n",
    "distorsions = []\n",
    "silhouette_scores = []\n",
    "for n in range(2, 11):\n",
    "    est = KMeans(n_clusters=n, random_state = RANDOM_STATE)\n",
    "    predicted = est.fit_predict(df2)\n",
    "    distorsions.append(est.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(df2, predicted))\n",
    "\n",
    "\n",
    "# (loosely based on some lines by Claudio Sartori)\n",
    "def two_scale_plot(x_data, x_label, *y_tups, colors=('tab:red', 'tab:blue')):\n",
    "    # https://matplotlib.org/3.1.0/gallery/color/named_colors.html\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax = (ax1, ax1.twinx())\n",
    "    ax1.set_xlabel(x_label)\n",
    "    for i, (y_data, y_label) in enumerate(y_tups):\n",
    "        ax[i].set_ylabel(y_label, color=colors[i])\n",
    "        ax[i].plot(x_data, y_data, color=colors[i])\n",
    "        ax[i].tick_params(axis='y', labelcolor=colors[i])\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "K_range = range(2,11)\n",
    "# two_scale_plot(K_range, 'n', (silhouette_scores, 'silhouette'), (distorsions, 'distorsion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ALWAYS check this manually looking at the plot! ---\n",
    "optimal_n_clusters = max(zip(K_range, silhouette_scores), key=lambda _:_[1])[0]\n",
    "\n",
    "# We can now build the classifier with the optimal parameter:\n",
    "est = KMeans(n_clusters=optimal_n_clusters, random_state=RANDOM_STATE)\n",
    "predicted = est.fit_predict(df2)\n",
    "# plot_clusters(np.array(df2), predicted, (0,1), est.cluster_centers_)\n",
    "# print(f'Distortion: {est.inertia_:2.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette plots\n",
    "( Code by **Claudio Sartori**, slightly adapted and enhanced. Originally in plot_silhouette.py )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "def plot_silhouette(silhouette_vals, y, colors = cm.tab10):\n",
    "    \"\"\"\n",
    "    Plotting silhouette scores for the individual samples of a labelled data set.\n",
    "    The scores will be grouped according to labels and sorted in descending order.\n",
    "    The bars are proportional to the score and the color is determined by the label.\n",
    "    \n",
    "    silhouette_vals: the silhouette values of the samples\n",
    "    y:               the labels of the samples\n",
    "    \n",
    "    \"\"\"\n",
    "    cluster_labels = np.unique(y)\n",
    "    n_clusters = len(cluster_labels)\n",
    "    y_ax_lower, y_ax_upper = 0, 0\n",
    "    yticks = []\n",
    "    for i, c in enumerate(cluster_labels): # generate pairs index, cluster_label\n",
    "        c_silhouette_vals = silhouette_vals[[_==c for _ in y]] # extracts records with the current cluster label\n",
    "        c_silhouette_vals.sort() # sort the silhouette vals for the current class\n",
    "        y_ax_upper += len(c_silhouette_vals)\n",
    "        color = colors(i / n_clusters)\n",
    "        plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0, \n",
    "                edgecolor='none', color=color)\n",
    "        yticks.append((y_ax_lower + y_ax_upper) / 2)\n",
    "        y_ax_lower += len(c_silhouette_vals)\n",
    "\n",
    "        c_silhouette_avg = np.mean(c_silhouette_vals)\n",
    "        plt.axvline(c_silhouette_avg, color=color, linestyle=\"--\", ymax=(y_ax_upper-1)/len(silhouette_vals))\n",
    "\n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    plt.axvline(silhouette_avg, color='black', linestyle=\":\")\n",
    "    plt.yticks(yticks, cluster_labels)# + 1)\n",
    "    plt.ylabel('Cluster')\n",
    "    plt.xlabel('Silhouette coefficient')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('./figures/silhouette.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import silhouette_samples\n",
    "# plot_silhouette(silhouette_samples(df2, predicted, metric='euclidean'), predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just loading data:\n",
    "names = ['Class','age','menopause','tumor-size','inv-nodes',\n",
    "         'node-caps','deg-malig','breast','breast-quad','irradiat']\n",
    "df = pd.read_csv('breast-cancer.data', names = names, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning values, example of the missing zeros:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use eg: \"print(df['tumor-size'].unique())\" to check.\n",
    "\n",
    "from re import sub\n",
    "def pretty(_): return sub(r'^(\\d)-', r'0\\1-', sub(r'-(\\d)$', r'-0\\1', _))\n",
    "\n",
    "df['tumor-size'] = df['tumor-size'].map(pretty)\n",
    "df['inv-nodes'] = df['inv-nodes'].map(pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Values transformation (encoding)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPARATE DIFFERENT KIND OF ATTRIBUTES:\n",
    "non_numeric = list(df.dtypes[df.dtypes!=np.int64].keys())\n",
    "numeric = ['deg-malig']\n",
    "ordinal = ['age', 'tumor-size', 'inv-nodes']\n",
    "categorical = ['irradiat', 'breast-quad', 'menopause', 'node-caps', 'breast']\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# PREPARE THE TRANSFORMERS AND THE \"COMPOSITE\" TRANSFORMER:\n",
    "transf_dtype = np.int32\n",
    "categorical_transformer = OneHotEncoder(\n",
    "    handle_unknown='ignore',\n",
    "    sparse = False,\n",
    "    dtype = transf_dtype)\n",
    "ordinal_transformer = OrdinalEncoder(dtype = transf_dtype)\n",
    "trans_list = [('cat', categorical_transformer, categorical), ('ord', ordinal_transformer, ordinal)]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = trans_list,\n",
    "    remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "# Separate target:\n",
    "y = df['Class']\n",
    "X = df.drop(columns='Class')\n",
    "class_labels = y.unique()\n",
    "\n",
    "# That's only needed for some scoring functions eg. accuracy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lenc = LabelEncoder()\n",
    "y_enc = lenc.fit_transform(y)\n",
    "\n",
    "# WE CAN NOW FIT-TRANSFORM THE PREPROCESSOR:\n",
    "# preprocessor.fit(X)\n",
    "X_p = preprocessor.fit_transform(X, y_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nicely visualize the transformed data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right now this f. handles correctly only transformers that do not change\n",
    "# the number of columns with the exception of OneHotEncoder.\n",
    "def preprocessed_mat_to_df(preproc, mat, orig_df):\n",
    "    estim_cols = set()\n",
    "    labels = []\n",
    "    remainder_is_pt = False\n",
    "    for enc_name,enc,cols in preproc.transformers_:\n",
    "        if enc_name=='remainder' and enc in ['passthrough', 'drop']:\n",
    "            if enc=='passthrough': remainder_is_pt = True\n",
    "            continue\n",
    "        estim_cols |= set(cols)\n",
    "        for col in cols:\n",
    "            if isinstance(enc, OneHotEncoder):\n",
    "                labels += [f'{col}_{n}' for n in range(1,len(orig_df[col].unique())+1)]\n",
    "            else: labels += [f'{col}']\n",
    "    if remainder_is_pt: labels += list(set(orig_df.columns)-estim_cols)\n",
    "    return pd.DataFrame(X_p, columns=labels)\n",
    "\n",
    "X_p_df = preprocessed_mat_to_df(preprocessor, X_p, X)\n",
    "#X_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
