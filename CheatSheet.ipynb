{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML lab cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Output has been removed for brevity, uncomment to visualize it!\n",
    "\n",
    "**NOTE:** This file only contains very common stuff or code which is not easy remember; don't take this as a complete reference (not yet at least)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual check for decimal separator, delimiter etc.:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"winequality-red.csv\"\n",
    "\n",
    "with open(data_file) as file_:\n",
    "    # print(file_.readline(), '\\n', file_.readline())\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import as a dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file, sep=';', decimal='.')\n",
    "\n",
    "# print(f'Shape of the input data {df.shape}\\n')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example:\n",
    "data_file = 'ex1_4dim_data.csv'\n",
    "df2 = pd.read_csv(data_file, delimiter=',', names=['col1', 'col2', 'col3', 'col4']) # or use: header=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import as numpy array:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array_ = np.loadtxt(data_file, delimiter = ',', skiprows=1)\n",
    "#array_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# here warning are ignored\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same implemented as a handy decorator:\n",
    "def no_warn(decd):\n",
    "    import warnings\n",
    "    def f(*args, **kargs):\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        decd(*args, **kargs)\n",
    "        warnings.resetwarnings()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphically analyze a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understand relations between attributes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# df.hist(figsize = [15,10]); # [x, y]\n",
    "\n",
    "import seaborn as sns\n",
    "# no_warn(sns.pairplot)(df[:10], hue='quality', corner=True);\n",
    "\n",
    "# sns.heatmap(df.corr(), cmap=\"YlGnBu\", annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplots (detect outliers...):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(data = df);\n",
    "\n",
    "# Better, esp. with non-normalized data:\n",
    "import matplotlib.pyplot as plt\n",
    "def boxplots(df):\n",
    "    plt.figure(figsize=(17,10))\n",
    "    pos = 1\n",
    "    for i in df.columns:\n",
    "        plt.subplot(3, 4, pos)\n",
    "        sns.boxplot(x = df[i], width=.5)\n",
    "        pos += 1\n",
    "    plt.show()\n",
    "\n",
    "# boxplots(df)\n",
    "\n",
    "# To compare only two (categ.) atttributes:\n",
    "# sns.boxplot(x='quality', y='fixed acidity', data = df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data for supervised learning\n",
    "\n",
    "see also: Optimizing decision tree by train-validation-test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ = 'quality'\n",
    "RANDOM_STATE = 44\n",
    "\n",
    "y = df[class_]\n",
    "X = df.drop(columns=class_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train/test split:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tup = train_test_split(\n",
    "    X, y,\n",
    "    random_state=RANDOM_STATE,\n",
    "    train_size = 0.66             # 0.75 default\n",
    ")\n",
    "\n",
    "n_features = X_train.shape[1]     \n",
    "# assert(n_features==X_test.shape[1])\n",
    "\n",
    "# for _ in Tup: print(end=f'{_.shape} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with decision tree (with _Simple Holdout_ testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "DTCLASSIF_PARS = {'criterion':'entropy'}\n",
    "\n",
    "def instantiate_and_predict(X_data, y_target, X_to_predict, **pars):\n",
    "    global RANDOM_STATE, DTCLASSIF_PARS\n",
    "    estim = tree.DecisionTreeClassifier(**pars, **DTCLASSIF_PARS, random_state=RANDOM_STATE)\n",
    "    estim.fit(X_data, y_target)\n",
    "    return (estim, estim.predict(X_to_predict))\n",
    "\n",
    "model, tr_predicted = instantiate_and_predict(X_train, y_train, X_train)\n",
    "test_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation-test loop\n",
    "### (Optimizing decision tree changing depth, testing with a validation set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data:**\n",
    "\n",
    "( Note that in this notebook we could have splitted further X_train and y_train. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1\n",
    "def train_validation_test_split(X, y, proportion=(.6, .3, .1), **args):\n",
    "    ts1, ts2 = proportion[0], round(proportion[1]/(1-proportion[0]), 4)\n",
    "    X_train, X_to_split, y_train, y_to_split = train_test_split(X, y, **args, train_size=ts1)\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_to_split, y_to_split, **args, train_size=ts2)\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "\n",
    "Tup = train_validation_test_split(X, y, random_state=RANDOM_STATE)\n",
    "X_train,X_valid,X_test,y_train,y_valid,y_test = Tup\n",
    "\n",
    "# for _ in Tup: print(end=f'{_.shape} ')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiating and fitting a DecisionTree without depth limit to get max. depth:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(**DTCLASSIF_PARS, random_state=RANDOM_STATE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#init_impurity = model.tree_.impurity[0]\n",
    "parameter_values=range(1, model.tree_.max_depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiating and fitting DecisionTrees with a certain depth:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for par in parameter_values:\n",
    "    _, y_predicted = instantiate_and_predict(X_train, y_train, X_valid, max_depth=par)\n",
    "    scores.append(accuracy_score(y_valid, y_predicted))\n",
    "\n",
    "# scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the accuracy and computing max:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trend(data_x, data_y, x_lab='x', y_lab='y', title=''):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(data_x, data_y, '-o', linewidth=1, markersize=10)\n",
    "    min_ , max_ = plt.ylim()\n",
    "    rg = max_ - min_\n",
    "    plt.xlabel(x_lab, fontsize=18)\n",
    "    plt.xticks(data_x)\n",
    "    for i,_ in enumerate(data_x): plt.axvline(_, color='gray', linestyle=\":\", ymax=(data_y[i]-min_)/rg)\n",
    "    plt.ylabel(y_lab, fontsize=18)\n",
    "    if title: plt.title(title, fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "'''\n",
    "plot_trend(\n",
    "    parameter_values,\n",
    "    scores,\n",
    "    'max_depth', 'accuracy', \"Accuracy on validation set varying max_depth of tree\"\n",
    ")'''\n",
    "\n",
    "NEW_DEPTH = parameter_values[np.argmax(scores)]\n",
    "# print(f'Validation: The best accuracy is obtained with DEPTH = {NEW_DEPTH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiating and fitting the final DecisionTree:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use the unlimited-depth tree to compare the accuracy:\n",
    "pred1 = model.predict(X_test)\n",
    "#model, pred1 = instantiate_and_predict(X_train, y_train, X_test)\n",
    "\n",
    "# Instantiating and fitting the final DecisionTree:\n",
    "new_model, pred2 = instantiate_and_predict(X_train, y_train, X_test, max_depth=NEW_DEPTH)\n",
    "\n",
    "# print_accuracy('pred1', y_test)\n",
    "# print_accuracy('pred2', y_test)\n",
    "# print(f'depth: {model.tree_.max_depth} --> {new_model.tree_.max_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!!!**\n",
    "\n",
    "The accuracy may either increase or decrease. What is better is the significance of the accuracy for the estimation of the accuracy when predicting with new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "### (Optimizing decision tree changing depth, testing with cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data and instantiating and fitting a DecisionTree without depth limit to get max. depth:**\n",
    "\n",
    "As before, but without the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RANDOM_STATE,train_size=0.66)\n",
    "\n",
    "model,_ = instantiate_and_predict(X_train, y_train, X_train)\n",
    "parameter_values = range(1, model.tree_.max_depth+1)\n",
    "# parameter_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiating and fitting\\* DecisionTrees with a certain depth:**\n",
    "    \n",
    "(\\*) This time we train/fit and validate multiple times, since we're using K-fold. This is handled by the method **cross_val_score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = []\n",
    "K = 5\n",
    "for par in parameter_values:\n",
    "    tmp_model = tree.DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=par, **DTCLASSIF_PARS)\n",
    "    # We only save the AVG accuracy over the cv partitions of the training set:\n",
    "    scores.append( np.mean(cross_val_score(\n",
    "        tmp_model, X_train, y_train, \n",
    "        scoring='accuracy',\n",
    "        cv = K\n",
    "    )) )\n",
    "    \n",
    "'''\n",
    "plot_trend(\n",
    "    parameter_values,\n",
    "    scores,\n",
    "    'max_depth', 'accuracy', f\"Average accuracy with {K}-fold cross-validation varying max_depth of tree\"\n",
    ")'''\n",
    "\n",
    "NEW_DEPTH = parameter_values[np.argmax(scores)]\n",
    "# print(f'Validation: The best accuracy is obtained with DEPTH = {NEW_DEPTH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remainin part see **Instantiating and fitting the final DecisionTree** of the chapter _Train-validation-test loop_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!!!**\n",
    "\n",
    "The accuracy may either increase or decrease. What is better is the significance of the accuracy for the estimation of the accuracy when predicting with new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "'''\n",
    "plt.figure(figsize=(17,22))\n",
    "plot_tree(\n",
    "    model,\n",
    "    feature_names=df.columns,\n",
    "    class_names=class_,\n",
    "    rounded = True,\n",
    "    proportion = True\n",
    ")''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy and other metrics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to have some data to use:\n",
    "test_predicted = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def print_accuracy(s1_name, s2):\n",
    "    accur = accuracy_score(eval(s1_name), s2)*100\n",
    "    print(f'The accuracy on {s1_name} is {accur:.4}%')\n",
    "    return accur\n",
    "    \n",
    "# print_accuracy('y_test', test_predicted);\n",
    "\n",
    "# # import sklearn.metrics as skm\n",
    "# # sorted([ _ for _ in skm.__all__ if 'score' in _])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "order = sorted(y_test.unique())\n",
    "# confusion_matrix(y_test, test_predicted, labels=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: BAD CODE\n",
    "# This is just to rember the meaning of this matrix. Never use this code in exams :-)\n",
    "def pretty(y_test, test_predicted, classes_):\n",
    "    classes = [str(_)[0] for _ in classes_]\n",
    "    real = 'real' + ' '*len(classes)\n",
    "    cm = confusion_matrix(y_test, test_predicted, labels=classes_)\n",
    "    cm_spl = (' ' + str(cm).replace('[','').replace(']','')).split('\\n')\n",
    "    row_l = len(cm_spl[0])\n",
    "    l = row_l//len(cm[0])\n",
    "    print(end='    |  predicted as\\n    | ')\n",
    "    for _ in classes: print(end=' '*(l-len(str(_)))+str(_))\n",
    "    print('\\n  __|'+'_'*(row_l+3))\n",
    "    for i,c in enumerate(classes): print(real[i], c, '|', cm_spl[i])\n",
    "    print()\n",
    "    \n",
    "# pretty(y_test, test_predicted, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Centroids (having the labels)\n",
    "See _Plot Points_ section for examples about these functions. \\\n",
    "See _Elbow Method_ section to know how to compute labels and centroids directly (using KMeans)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The fastest way:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroids2(arr, labels, **args):\n",
    "    from sklearn.neighbors import NearestCentroid\n",
    "    return NearestCentroid(**args).fit(arr, labels).centroids_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without using sklearn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroids(arr, labels, FUN=np.mean):\n",
    "    centroids = []\n",
    "    ulabels = np.unique(labels)\n",
    "    for L in ulabels:\n",
    "        tr = arr[[_==L for _ in labels],:].transpose()\n",
    "        centroids.append([FUN(tr[_]) for _ in range(arr.shape[1])])\n",
    "    return np.array(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just points:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(df2.iloc[:,0:2])\n",
    "\n",
    "'''\n",
    "plt.xlabel(df2.iloc[:,0].name)\n",
    "plt.ylabel(df2.iloc[:,1].name)\n",
    "\n",
    "plt.plot(arr[:,0], arr[:,1], '.')\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trend (parameter/value):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "SEE _plot\\_trend_ function in _Train-validation-test loop_ chapter.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clusters (different colors and centroids):** \\\n",
    "( Code by **Claudio Sartori** slightly adapted for compatibility. Originally in plot_clusters.py )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "def plot_clusters(X, y, dim, points,\n",
    "                  labels_prefix = 'cluster ', \n",
    "                  points_name = 'centroids',\n",
    "                  colors = cm.tab10, # a qualitative map\n",
    "                  points_color = cm.tab10(10) # by default the last of the map (to be improved)\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Plot a two dimensional projection of an array of labelled points\n",
    "    X:      array with at least two columns\n",
    "    y:      vector of labels, length as number of rows in X\n",
    "    dim:    the two columns to project, inside range of X columns, e.g. (0,1)\n",
    "    points: additional points to plot as 'stars'\n",
    "    labels_prefix: prefix to the labels for the legend ['cluster']\n",
    "    points_name:   legend name for the additional points ['centroids']\n",
    "    colors: a color map\n",
    "    points_color: the color for the points\n",
    "    \"\"\"\n",
    "    # plot the labelled (colored) dataset and the points\n",
    "    labels = np.unique(y)\n",
    "    for i in range(len(labels)):\n",
    "        color = colors(i / len(labels)) # choose a color from the map\n",
    "        plt.scatter(X[[_==labels[i] for _ in y],dim[0]], \n",
    "                    X[[_==labels[i] for _ in y],dim[1]], \n",
    "                    s=10, c = [color], marker='s', label=labels_prefix+str(labels[i]))\n",
    "    plt.scatter(points[:,dim[0]], points[:,dim[1]], s=50, marker='*', c=[points_color], label=points_name)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "some_rand_labels = ['one' if arr[_][0]<-4.7 else 'two' if arr[_][0]<.7 else 'three' for _ in range(len(arr))]\n",
    "\n",
    "'''\n",
    "plot_clusters(\n",
    "    arr,\n",
    "    some_rand_labels,\n",
    "    (0,1),\n",
    "    centroids2(arr, some_rand_labels)                  # try to add eg: metric='manhattan'\n",
    "    # ALTERNATIVE: centroids(arr, some_rand_labels)    # try to add eg: FUN=np.median\n",
    ")''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elbow Method (includes KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Cicling over different KMeans estimators, one for each value of K in [2,10]:\n",
    "distorsions = []\n",
    "silhouette_scores = []\n",
    "for n in range(2, 11):\n",
    "    est = KMeans(n_clusters=n, random_state = RANDOM_STATE)\n",
    "    predicted = est.fit_predict(df2)\n",
    "    distorsions.append(est.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(df2, predicted))\n",
    "\n",
    "\n",
    "# (loosely based on some lines by Claudio Sartori)\n",
    "def two_scale_plot(x_data, x_label, *y_tups, colors=('tab:red', 'tab:blue')):\n",
    "    # https://matplotlib.org/3.1.0/gallery/color/named_colors.html\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax = (ax1, ax1.twinx())\n",
    "    ax1.set_xlabel(x_label)\n",
    "    for i, (y_data, y_label) in enumerate(y_tups):\n",
    "        ax[i].set_ylabel(y_label, color=colors[i])\n",
    "        ax[i].plot(x_data, y_data, color=colors[i])\n",
    "        ax[i].tick_params(axis='y', labelcolor=colors[i])\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "K_range = range(2,11)\n",
    "# two_scale_plot(K_range, 'n', (silhouette_scores, 'silhouette'), (distorsions, 'distorsion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ALWAYS check this manually looking at the plot! ---\n",
    "optimal_n_clusters = max(zip(K_range, silhouette_scores), key=lambda _:_[1])[0]\n",
    "\n",
    "# We can now build the classifier with the optimal parameter:\n",
    "est = KMeans(n_clusters=optimal_n_clusters, random_state=RANDOM_STATE)\n",
    "predicted = est.fit_predict(df2)\n",
    "# plot_clusters(np.array(df2), predicted, (0,1), est.cluster_centers_)\n",
    "# print(f'Distortion: {est.inertia_:2.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette plots\n",
    "( Code by **Claudio Sartori**, slightly adapted and enhanced. Originally in plot_silhouette.py )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "def plot_silhouette(silhouette_vals, y, colors = cm.tab10):\n",
    "    \"\"\"\n",
    "    Plotting silhouette scores for the individual samples of a labelled data set.\n",
    "    The scores will be grouped according to labels and sorted in descending order.\n",
    "    The bars are proportional to the score and the color is determined by the label.\n",
    "    \n",
    "    silhouette_vals: the silhouette values of the samples\n",
    "    y:               the labels of the samples\n",
    "    \n",
    "    \"\"\"\n",
    "    cluster_labels = np.unique(y)\n",
    "    n_clusters = len(cluster_labels)\n",
    "    y_ax_lower, y_ax_upper = 0, 0\n",
    "    yticks = []\n",
    "    silhouette_avgs = []\n",
    "    for i, c in enumerate(cluster_labels): # generate pairs index, cluster_label\n",
    "        c_silhouette_vals = silhouette_vals[[_==c for _ in y]] # extracts records with the current cluster label\n",
    "        c_silhouette_vals.sort() # sort the silhouette vals for the current class\n",
    "        y_ax_upper += len(c_silhouette_vals)\n",
    "        color = colors(i / n_clusters)\n",
    "        plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0, \n",
    "                edgecolor='none', color=color)\n",
    "        yticks.append((y_ax_lower + y_ax_upper) / 2)\n",
    "        mean = np.mean(c_silhouette_vals)\n",
    "        silhouette_avgs += [(mean, np.argwhere(c_silhouette_vals>=mean)[0][0]+y_ax_lower)]\n",
    "        y_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "    min_ , max_ = plt.ylim()\n",
    "    rg = max_ - min_\n",
    "    for index,(m,i) in enumerate(silhouette_avgs):\n",
    "        plt.axvline(m, color = colors(index / n_clusters), linestyle=\"--\", ymax=(i-min_)/rg)\n",
    "    silhouette_avgs = np.mean(silhouette_vals)\n",
    "    plt.axvline(silhouette_avgs, color='black', linestyle=\":\")\n",
    "    \n",
    "    plt.xticks(np.linspace(0,1,21))\n",
    "    plt.yticks(yticks, cluster_labels)# + 1)\n",
    "    plt.ylabel('Cluster')\n",
    "    plt.xlabel('Silhouette coefficient')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('./figures/silhouette.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import silhouette_samples\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plot_silhouette(silhouette_samples(df2, predicted, metric='euclidean'), predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just loading data:\n",
    "names = ['Class','age','menopause','tumor-size','inv-nodes',\n",
    "         'node-caps','deg-malig','breast','breast-quad','irradiat']\n",
    "df = pd.read_csv('breast-cancer.data', names = names, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning values, example of the missing zeros:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use eg: \"print(df['tumor-size'].unique())\" to check.\n",
    "\n",
    "from re import sub\n",
    "def pretty(_): return sub(r'^(\\d)-', r'0\\1-', sub(r'-(\\d)$', r'-0\\1', _))\n",
    "\n",
    "df['tumor-size'] = df['tumor-size'].map(pretty)\n",
    "df['inv-nodes'] = df['inv-nodes'].map(pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Values transformation (encoding)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPARATE DIFFERENT KIND OF ATTRIBUTES:\n",
    "non_numeric = list(df.dtypes[df.dtypes!=np.int64].keys())\n",
    "numeric = ['deg-malig']\n",
    "ordinal = ['age', 'tumor-size', 'inv-nodes']\n",
    "categorical = ['irradiat', 'breast-quad', 'menopause', 'node-caps', 'breast']\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# PREPARE THE TRANSFORMERS AND THE \"COMPOSITE\" TRANSFORMER:\n",
    "transf_dtype = np.int32\n",
    "categorical_transformer = OneHotEncoder(\n",
    "    handle_unknown='ignore',\n",
    "    sparse = False,\n",
    "    dtype = transf_dtype)\n",
    "ordinal_transformer = OrdinalEncoder(dtype = transf_dtype)\n",
    "trans_list = [('cat', categorical_transformer, categorical), ('ord', ordinal_transformer, ordinal)]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = trans_list,\n",
    "    remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "# Separate target:\n",
    "y = df['Class']\n",
    "X = df.drop(columns='Class')\n",
    "class_labels = y.unique()\n",
    "\n",
    "# That's only needed for some scoring functions eg. accuracy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lenc = LabelEncoder()\n",
    "y_enc = lenc.fit_transform(y)\n",
    "\n",
    "# WE CAN NOW FIT-TRANSFORM THE PREPROCESSOR:\n",
    "# preprocessor.fit(X)\n",
    "X_p = preprocessor.fit_transform(X, y_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nicely visualize the transformed data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right now this f. handles correctly only transformers that do not change\n",
    "# the number of columns with the exception of OneHotEncoder.\n",
    "def preprocessed_mat_to_df(preproc, mat, orig_df):\n",
    "    estim_cols = set()\n",
    "    labels = []\n",
    "    remainder_is_pt = False\n",
    "    for enc_name,enc,cols in preproc.transformers_:\n",
    "        if enc_name=='remainder' and enc in ['passthrough', 'drop']:\n",
    "            if enc=='passthrough': remainder_is_pt = True\n",
    "            continue\n",
    "        estim_cols |= set(cols)\n",
    "        for col in cols:\n",
    "            if isinstance(enc, OneHotEncoder):\n",
    "                labels += [f'{col}_{n}' for n in range(1,len(orig_df[col].unique())+1)]\n",
    "            else: labels += [f'{col}']\n",
    "    if remainder_is_pt: labels += list(set(orig_df.columns)-estim_cols)\n",
    "    return pd.DataFrame(X_p, columns=labels)\n",
    "\n",
    "X_p_df = preprocessed_mat_to_df(preprocessor, X_p, X)\n",
    "#X_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
